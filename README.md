# Smart Logistics Dataset Analysis and Predictive Modeling
I selected smart_logistics_dataset and apply the entire predictive analytics workflow, including data exploration, cleaning, business question formulation, model building, and insight generation. This project simulates real-world scenarios and will help me develop practical skills in data analytics.

## Objective
- Analyze factors influencing logistics delays, such as traffic, waiting time, and inventory levels.
- Build predictive models to forecast logistics delays using Logistic Regression and Random Forest.
- Optimize asset utilization by analyzing the relationship between traffic conditions and asset usage.

This project provides a comprehensive analysis of logistics data that can help companies reduce delays and improve resource management.

## Dataset
The dataset used for this project is the **Smart Logistics Supply Chain Dataset** from Kaggle, which provides real-time logistics data for 2024. It includes variables such as asset IDs, traffic conditions, waiting times, environmental factors (e.g., temperature, humidity), and logistics delays.

Source: [Smart Logistics Supply Chain Dataset](https://www.kaggle.com/datasets/ziya07/smart-logistics-supply-chain-dataset/data?select=smart_logistics_dataset.csv)

### Key Features:
- **Timestamp**: Time the data was recorded.
- **Asset_ID**: Unique identifier for the logistics assets.
- **Latitude & Longitude**: Geospatial data for tracking assets.
- **Inventory_Level**: Current inventory level of the asset.
- **Shipment_Status**: Status of the shipment (e.g., "In Transit", "Delivered", "Delayed").
- **Temperature & Humidity**: Environmental data recorded during transportation.
- **Traffic_Status**: Describes traffic conditions affecting delivery.
- **Waiting_Time**: Time spent waiting during logistics operations.
- **User_Transaction_Amount**: Monetary amount associated with user transactions.
- **Logistics_Delay**: Binary variable indicating a delay (1) or no delay (0).

## Tools and Libraries Used
This project uses the following tools and libraries:
- **Python** for data analysis and modeling.
- **Pandas** for data manipulation and cleaning.
- **Scikit-learn** for predictive modeling (Logistic Regression, Random Forest).
- **Matplotlib/Seaborn** for data visualization.
- **Google Colab** for running the notebook and sharing results.

## How to run the Project
Open the notebook in Google Colab

[Google Colab](https://colab.research.google.com/drive/1m8iyeLipGk9hnwYUb-QR_7IFKxN-wJry?usp=drive_link) 

## Final Report

The detailed analysis and results of the project are documented in the final report.

[Download Final Report (PDF)](https://drive.google.com/file/d/1b41knILgKYf9hAe3LilmTXV1EHbe3fJ6/view?usp=drive_link)
